{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13510352,"sourceType":"datasetVersion","datasetId":8571414}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Importation & Lib :** ","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade --quiet bitsandbytes triton accelerate transformers\n!pip install -q --upgrade transformers accelerate peft trl faiss-cpu\n!pip install -q wandb","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"TRANSFORMERS_NO_ADDITIONAL_CHAT_TEMPLATES\"] = \"1\"\nos.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n\nimport sys, importlib\nimport transformers\nimport datasets\nimport trl\nimport tqdm\nimport json, random, re, numpy as np, pandas as pd\nfrom datasets import load_dataset, Dataset  \nfrom transformers import AutoTokenizer\nimport torch, faiss\nfrom transformers import AutoTokenizer, AutoModel\nfrom collections import Counter, defaultdict\nimport bitsandbytes, triton\nfrom transformers import (\n    AutoTokenizer,  \n    AutoModelForCausalLM,\n    TrainingArguments\n)\nfrom peft import LoraConfig, prepare_model_for_kbit_training\nfrom kaggle_secrets import UserSecretsClient\nfrom trl import SFTConfig, SFTTrainer\n\nprint(\"‚úÖ All libraries imported successfully!\")\nprint(\"\\n\" + \"=\"*50)\nprint(\"‚úÖ LIBRARY VERSION CHECK ‚úÖ\")\nprint(\"=\"*50)\nprint(f\"üêç Python: {sys.version.split()[0]}\")\nprint(\"\\n--- Core Libraries ---\")\nprint(f\"üî• Torch: {torch.__version__} | CUDA: {torch.version.cuda}\")\nprint(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\nprint(\"\\n--- Hugging Face Ecosystem ---\")\nprint(f\"ü§ó Transformers: {transformers.__version__}\")\nprint(f\"üìì Datasets: {datasets.__version__}\")\nprint(f\"üß™ TRL: {trl.__version__}\")\nprint(\"\\n--- Hardware & Optimization ---\")\nprint(f\"‚ö° BitsAndBytes: {bitsandbytes.__version__}\")\nprint(f\"üî± Triton: {triton.__version__}\")\nprint(\"\\n--- Data & Utility ---\")\nprint(f\"üìä Numpy: {np.__version__}\")\nprint(f\"üìà Pandas: {pd.__version__}\")\nprint(f\"üîç Faiss: {faiss.__version__}\")\nprint(f\"‚è≥ Tqdm: {tqdm.__version__}\") \nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T11:40:51.036874Z","iopub.execute_input":"2025-10-29T11:40:51.037878Z","iopub.status.idle":"2025-10-29T11:40:51.045917Z","shell.execute_reply.started":"2025-10-29T11:40:51.037846Z","shell.execute_reply":"2025-10-29T11:40:51.045317Z"}},"outputs":[{"name":"stdout","text":"‚úÖ All libraries imported successfully!\n\n==================================================\n‚úÖ LIBRARY VERSION CHECK ‚úÖ\n==================================================\nüêç Python: 3.11.13\n\n--- Core Libraries ---\nüî• Torch: 2.6.0+cu124 | CUDA: 12.4\n‚úÖ CUDA available: True\n\n--- Hugging Face Ecosystem ---\nü§ó Transformers: 4.57.1\nüìì Datasets: 4.1.1\nüß™ TRL: 0.24.0\n\n--- Hardware & Optimization ---\n‚ö° BitsAndBytes: 0.48.1\nüî± Triton: 3.2.0\n\n--- Data & Utility ---\nüìä Numpy: 1.26.4\nüìà Pandas: 2.2.3\nüîç Faiss: 1.12.0\n‚è≥ Tqdm: 4.67.1\n==================================================\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T11:27:12.117679Z","iopub.execute_input":"2025-10-29T11:27:12.118088Z","iopub.status.idle":"2025-10-29T11:27:12.142605Z","shell.execute_reply.started":"2025-10-29T11:27:12.118061Z","shell.execute_reply":"2025-10-29T11:27:12.141605Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/bert-embeddings/bert_embeddings.npy\n/kaggle/input/bert-embeddings/ft_news_dialogue_FINAL_2.jsonl\n/kaggle/input/bert-embeddings/news_dialogue_two_roles.json\n/kaggle/input/bert-embeddings/news_dialogue.json\n/kaggle/input/bert-embeddings/news_articles_cleaned_for_bert.csv\n/kaggle/input/bert-embeddings/ft_news_dialogue_host_interview.jsonl\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# -----------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"-----------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# **1. Topic Semantic Search**","metadata":{}},{"cell_type":"code","source":"# ------------------------------------------------------------\n# 1. Load embeddings and cleaned dataset\n# ------------------------------------------------------------\ntry:\n    embeddings = np.load(\"/kaggle/input/bert-embeddings/bert_embeddings.npy\")\n    df = pd.read_csv(\"/kaggle/input/bert-embeddings/news_articles_cleaned_for_bert.csv\")\nexcept FileNotFoundError:\n    print(\"‚ùå Error: Could not find input files.\")\n    print(\"Please ensure '/kaggle/input/bert-embeddings/bert_embeddings.npy' and\")\n    print(\"'/kaggle/input/bert-embeddings/news_articles_cleaned_for_bert.csv' exist.\")\n    # Stop execution if files aren't found\n    raise\n\nprint(f\"Embeddings: {embeddings.shape[0]} | Dataset rows: {len(df)}\")\n\n# --- FIXED SYNTAX ERROR ---\n# Removed the stray code \", gs, axis=1, keepdims=True)\"\nassert len(df) == embeddings.shape[0], \"‚ùå Mismatch between embeddings and dataset rows!\"\nprint(\"‚úÖ Data loaded and verified.\")\n\n# ------------------------------------------------------------\n# 2. Build & save FAISS index\n# ------------------------------------------------------------\nindex = faiss.IndexFlatIP(embeddings.shape[1])  # Inner product ‚âà cosine\nindex.add(embeddings)\nfaiss.write_index(index, \"topic_retriever.index\")\n\n# Save category labels aligned with embeddings\ndf[\"category\"].to_csv(\"topic_labels.csv\", index=False)\nprint(\"‚úÖ FAISS index and topic labels saved.\")\n\n# ------------------------------------------------------------\n# 3. Load same BERT model/tokenizer used for embeddings\n# ------------------------------------------------------------\nmodel_name = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device).eval()\nprint(f\"‚úÖ Model '{model_name}' loaded onto {device}.\")\n\n# --- FIXED NORMALIZATION & INDENTATION ---\ndef embed_text(text):\n    \"\"\"Encode new text into same vector space as dataset.\"\"\"\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=True,\n        max_length=512\n    )\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    with torch.no_grad():\n        outputs = model(**inputs)\n        last_hidden = outputs.last_hidden_state\n        mask = inputs[\"attention_mask\"].unsqueeze(-1).expand(last_hidden.size()).float()\n        sum_emb = torch.sum(last_hidden * mask, 1)\n        sum_mask = torch.clamp(mask.sum(1), min=1e-9)\n        mean_pool = sum_emb / sum_mask\n    emb = mean_pool.cpu().numpy()\n    \n    # --- THIS IS THE CORRECT NORMALIZATION ---\n    # The (1, 768) embedding is normalized along axis=1\n    norm = np.linalg.norm(emb, axis=1, keepdims=True)\n    emb = emb / (norm + 1e-9)  # Add epsilon for numerical stability\n    \n    return emb.astype(\"float32\")\n\n# ------------------------------------------------------------\n# 4. Load FAISS index & topic labels\n# ------------------------------------------------------------\nindex = faiss.read_index(\"topic_retriever.index\")\ntopics = pd.read_csv(\"topic_labels.csv\")[\"category\"].tolist()\nprint(\"‚úÖ FAISS index and labels re-loaded for inference.\")\n\n# ------------------------------------------------------------\n# 5. Example: predict topic of a new speech\n# ------------------------------------------------------------\n# --- FIXED INDENTATION ---\nspeech = \"We are moving from a mobile and cloud era to an era of ubiquitous computing and ambient intelligence, an era which will experience more digitization over the next 10 years than the last 40. Going forward, every business process will be collaborative, powered by data and AI, and will bridge the digital and physical worlds. One thing underlying everything is how large-scale AI models are becoming platforms in their own right, creating that ambient intelligence all around us.\"\n\nspeech_emb = embed_text(speech)\nD, I = index.search(speech_emb, k=10)  # Search for 10 nearest neighbors\nretrieved_topics = [topics[i] for i in I[0]]\n\n# Find the most common topic among the neighbors\npredicted = Counter(retrieved_topics).most_common(1)[0][0]\n\nprint(\"\\n\" + \"=\"*35)\nprint(\"     TOPIC RETRIEVAL RESULT\")\nprint(\"=\"*35)\nprint(\"User Speech:\")\nprint(f\"  '{speech}'\")\nprint(\"-----------------------------------\")\nprint(f\"Predicted Topic: {predicted}\")\nprint(\"===================================\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T11:27:15.662381Z","iopub.execute_input":"2025-10-29T11:27:15.662735Z","iopub.status.idle":"2025-10-29T11:27:21.763920Z","shell.execute_reply.started":"2025-10-29T11:27:15.662711Z","shell.execute_reply":"2025-10-29T11:27:21.763056Z"}},"outputs":[{"name":"stdout","text":"Embeddings: 6844 | Dataset rows: 6844\n‚úÖ Data loaded and verified.\n‚úÖ FAISS index and topic labels saved.\n‚úÖ Model 'bert-base-uncased' loaded onto cuda.\n‚úÖ FAISS index and labels re-loaded for inference.\n\n===================================\n     TOPIC RETRIEVAL RESULT\n===================================\nUser Speech:\n  'We are moving from a mobile and cloud era to an era of ubiquitous computing and ambient intelligence, an era which will experience more digitization over the next 10 years than the last 40. Going forward, every business process will be collaborative, powered by data and AI, and will bridge the digital and physical worlds. One thing underlying everything is how large-scale AI models are becoming platforms in their own right, creating that ambient intelligence all around us.'\n-----------------------------------\nPredicted Topic: TECH\n===================================\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# -----------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"----------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# **2. Data Filtration and Cleaning for finetuning use later :**","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# Inspect the uploaded MediaSum-like dataset (array format)\n# ============================================================\nINPUT_PATH = \"/kaggle/input/bert-embeddings/news_dialogue.json\"\n\n# Load full JSON or only first few entries if it's large\nwith open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nprint(f\"‚úÖ Loaded {len(data)} records\\n\")\n\n# Convert to DataFrame\ndf = pd.DataFrame(data)\nprint(\"Columns:\", df.columns.tolist(), \"\\n\")\n\n# Show one example in detail\nprint(df.iloc[1])\n\n# If it has utt/speaker, preview them\nif \"utt\" in df.columns and \"speaker\" in df.columns:\n    print(\"\\nFirst 3 utterances:\", df.iloc[0]['utt'][:3])\n    print(\"First 3 speakers:\", df.iloc[0]['speaker'][:3])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T11:27:25.501851Z","iopub.execute_input":"2025-10-29T11:27:25.502158Z","iopub.status.idle":"2025-10-29T11:28:34.920908Z","shell.execute_reply.started":"2025-10-29T11:27:25.502139Z","shell.execute_reply":"2025-10-29T11:28:34.920085Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loaded 463596 records\n\nColumns: ['id', 'program', 'date', 'url', 'title', 'summary', 'utt', 'speaker'] \n\nid                                                     NPR-2\nprogram                               Weekend Edition Sunday\ndate                                              2016-10-23\nurl        https://www.npr.org/2016/10/23/499042298/young...\ntitle      Young, First-Time Voters Share Views On Electi...\nsummary    NPR's Rachel Martin speaks with young voters w...\nutt        [You have heard it again and again - this is a...\nspeaker    [RACHEL MARTIN, HOST, ASHANTI MARTINEZ, LAUREN...\nName: 1, dtype: object\n\nFirst 3 utterances: ['Now, moving on, Forest Whitaker as Moses, Tisha Campbell Martin as Mary Magdalene - well, that\\'s all in \"The Bible Experience.\" A New Testament edition was released in 2006. This edition is billed as \"The Complete Bible.\" It doesn\\'t have one person reading the gospels. It features nearly 400 African-American artists, actors and ministers, plus sound effects.', \"Just listen to Blair Underwood's rendition of Jesus on the cross.\", '(As Jesus) My God, my God, why have you forsaken me?']\nFirst 3 speakers: ['FARAI CHIDEYA, host', 'FARAI CHIDEYA, host', 'Mr. BLAIR UNDERWOOD (Actor)']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================================\n# Analyze alignment and length statistics\n# ============================================================\nINPUT_PATH = \"/kaggle/input/bert-embeddings/news_dialogue.json\"\n\nwith open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\n# Verify alignment\nutt_lens = [len(d[\"utt\"]) for d in data]\nspk_lens = [len(d[\"speaker\"]) for d in data]\naligned_mask = [u == s for u, s in zip(utt_lens, spk_lens)]\naligned = sum(aligned_mask)\nprint(f\"‚úÖ {aligned:,}/{len(data):,} dialogues have matching utt/speaker lengths \"\n      f\"({aligned/len(data)*100:.2f}% alignment).\\n\")\n\n# Compute averages and percentiles\nutt_arr = np.array(utt_lens)\nprint(f\"üó£Ô∏è Average number of utterances per dialogue: {utt_arr.mean():.2f}\")\nprint(f\"üîπ Median: {np.median(utt_arr):.0f}\")\nprint(f\"üîπ 90th percentile: {np.percentile(utt_arr, 90):.0f}\")\nprint(f\"üîπ 99th percentile: {np.percentile(utt_arr, 99):.0f}\")\nprint(f\"üìè Min: {utt_arr.min()} | Max: {utt_arr.max()}\\n\")\n\n# Show one well-formed example\nfor d in data:\n    if len(d[\"utt\"]) == len(d[\"speaker\"]):\n        print(\"--- Example dialogue ---\")\n        for u, s in zip(d[\"utt\"][:8], d[\"speaker\"][:8]):  # show first 8 turns\n            print(f\"{s}: {u}\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T11:30:16.981983Z","iopub.execute_input":"2025-10-29T11:30:16.982363Z","iopub.status.idle":"2025-10-29T11:30:49.435193Z","shell.execute_reply.started":"2025-10-29T11:30:16.982339Z","shell.execute_reply":"2025-10-29T11:30:49.434512Z"}},"outputs":[{"name":"stdout","text":"‚úÖ 463,596/463,596 dialogues have matching utt/speaker lengths (100.00% alignment).\n\nüó£Ô∏è Average number of utterances per dialogue: 30.02\nüîπ Median: 21\nüîπ 90th percentile: 56\nüîπ 99th percentile: 188\nüìè Min: 1 | Max: 2827\n\n--- Example dialogue ---\nFARAI CHIDEYA, host: Now, moving on, Forest Whitaker as Moses, Tisha Campbell Martin as Mary Magdalene - well, that's all in \"The Bible Experience.\" A New Testament edition was released in 2006. This edition is billed as \"The Complete Bible.\" It doesn't have one person reading the gospels. It features nearly 400 African-American artists, actors and ministers, plus sound effects.\nFARAI CHIDEYA, host: Just listen to Blair Underwood's rendition of Jesus on the cross.\nMr. BLAIR UNDERWOOD (Actor): (As Jesus) My God, my God, why have you forsaken me?\nFARAI CHIDEYA, host: Now, we've got two people affiliated with the project with us today. Kyle Bowser, he co-produced \"The Bible Experience\" and actress Wendy Raquel Robinson, one of the actors in \"The Bible Experience,\" and she also stars in the CW series, \"The Game.\"\nFARAI CHIDEYA, host: Hi folks, how are you doing?\nMs. WENDY RAQUEL ROBINSON (Actress): Great.\nMr. KYLE BOWSER (Co-producer, \"The Bible Experience: The Complete Bible\"): Great. How are you?\nFARAI CHIDEYA, host: I'm doing great. Now, Kyle, how did this project come about?\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ============================================================\n# Analyze token length and speaker role vocabulary\n# ============================================================\nINPUT_PATH = \"/kaggle/input/bert-embeddings/news_dialogue.json\"\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\nwith open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\n# --- Compute token counts on a sample ---\nsample_size = 5000  # adjust for speed\ntoken_counts = []\nfor d in data[:sample_size]:\n    for utt in d[\"utt\"]:\n        n_tokens = len(tokenizer.encode(utt, add_special_tokens=False))\n        token_counts.append(n_tokens)\n\ntoken_counts = np.array(token_counts)\nprint(f\"üßæ Sample size: {len(token_counts):,} utterances\")\nprint(f\"Average tokens per utterance: {token_counts.mean():.2f}\")\nprint(f\"Median: {np.median(token_counts):.0f}\")\nprint(f\"90th percentile: {np.percentile(token_counts,90):.0f}\")\nprint(f\"Max: {token_counts.max()}\\n\")\n\n# --- Extract role descriptors from speaker strings ---\nrole_pattern = re.compile(r\"(?:,|[\\(])\\s*([A-Za-z\\s\\&\\.]+?)(?:[\\)\\,]|$)\")\nroles = []\n\nfor d in data[:20000]:  # sample 20k dialogues for coverage\n    for spk in d[\"speaker\"]:\n        match = role_pattern.search(spk)\n        if match:\n            role = match.group(1).strip().upper()\n            # remove clutter like \"MR.\" \"MS.\" etc.\n            role = re.sub(r\"\\b(MR|MS|MRS|DR|PROF|THE|A|AN)\\b\\.?\\s*\", \"\", role)\n            roles.append(role)\n\nrole_counts = Counter(roles)\nprint(f\"üéôÔ∏è Found {len(role_counts)} distinct role descriptors.\\n\")\n\n# Display top 30 most frequent roles\nfor role, freq in role_counts.most_common(40):\n    print(f\"{role:40s} {freq}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T11:30:54.596861Z","iopub.execute_input":"2025-10-29T11:30:54.597590Z","iopub.status.idle":"2025-10-29T11:32:22.637240Z","shell.execute_reply.started":"2025-10-29T11:30:54.597563Z","shell.execute_reply":"2025-10-29T11:32:22.636244Z"}},"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"üßæ Sample size: 205,854 utterances\nAverage tokens per utterance: 48.05\nMedian: 40\n90th percentile: 102\nMax: 1051\n\nüéôÔ∏è Found 4094 distinct role descriptors.\n\nHOST                                     240830\nBYLINE                                   69938\nCALLER                                   14512\nAUTHOR                                   6088\nDIRECTOR                                 2447\nCOLUMNIST                                2360\nDEMOCRAT                                 1789\nPRESIDENT                                1727\nEXECUTIVE DIRECTOR                       1573\nREPORTER                                 1441\nACTOR                                    1191\nREPUBLICAN                               1073\nEDITOR                                   1029\nWRITER                                   1003\nSINGER                                   755\nFOUNDER                                  661\nSENIOR FELLOW                            600\nMUSICIAN                                 588\nEDITORIAL WRITER                         475\nCOMEDIAN                                 447\nVICE PRESIDENT                           411\nCORRESPONDENT                            391\nSLATE                                    380\nPH                                       370\nSENIOR EDITOR                            370\nSTAFF WRITER                             368\nHISTORY                                  360\nNEW YORK TIMES                           355\nRESIDENT                                 346\nPROFESSOR                                346\nREPORTING                                335\nJOURNALIST                               330\nACTRESS                                  329\nCEO                                      325\nCHAIRMAN                                 324\nPRESIDENT AND CEO                        322\nOWNER                                    317\nPOLITICAL SCIENCE                        304\nASSOCIATE EDITOR                         294\nFILMMAKER                                288\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"INPUT_PATH = \"/kaggle/input/bert-embeddings/news_dialogue.json\"\nOUTPUT_PATH = \"news_dialogue_known_roles.json\"\n\nKNOWN_ROLES = {\n    \"HOST\", \"AUTHOR\", \"DIRECTOR\", \"DEMOCRAT\", \"PRESIDENT\",\n    \"EXECUTIVE DIRECTOR\", \"ACTOR\", \"REPUBLICAN\", \"WRITER\",\n    \"FOUNDER\", \"VICE PRESIDENT\", \"PROFESSOR\", \"CEO\",\n    \"CHAIRMAN\", \"PRESIDENT AND CEO\", \"OWNER\"\n}\n\nrole_pattern = re.compile(r\"(?:,|[\\(])\\s*([A-Za-z\\s\\&\\.]+?)(?:[\\)\\,]|$)\")\n\ndef extract_role(spk: str) -> str:\n    match = role_pattern.search(spk)\n    if match:\n        role = match.group(1).strip().upper()\n        role = re.sub(r\"\\b(MR|MS|MRS|DR|PROF|THE|A|AN)\\b\\.?\\s*\", \"\", role)\n        return role\n    return \"\"\n\nwith open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nclean_data = []\nfor d in tqdm.tqdm(data, desc=\"Filtering dialogues\"):\n    roles = {extract_role(s) for s in d[\"speaker\"] if s}\n    if roles and all(r in KNOWN_ROLES for r in roles):\n        clean_data.append(d)\n\nprint(f\"‚úÖ Filtered dataset: {len(clean_data):,} dialogues kept\")\n\nwith open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n    json.dump(clean_data, f, ensure_ascii=False, indent=2)\n\nprint(f\"üíæ Saved filtered dataset to '{OUTPUT_PATH}'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T11:35:13.236916Z","iopub.execute_input":"2025-10-29T11:35:13.237907Z","iopub.status.idle":"2025-10-29T11:36:02.587616Z","shell.execute_reply.started":"2025-10-29T11:35:13.237877Z","shell.execute_reply":"2025-10-29T11:36:02.586943Z"}},"outputs":[{"name":"stderr","text":"Filtering dialogues: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 463596/463596 [00:09<00:00, 47582.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Filtered dataset: 4,216 dialogues kept\nüíæ Saved filtered dataset to 'news_dialogue_known_roles.json'\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ============================================================\n# Keep only 2-role dialogues and compute average utt length per combo\n# ============================================================\nINPUT_PATH = \"news_dialogue_known_roles.json\"   \nOUTPUT_2ROLE_PATH = \"news_dialogue_two_roles.json\"\nOUTPUT_STATS_PATH = \"two_role_combo_stats.csv\"\n\n# ------------------------------------------------------------\n# Regex for role extraction\n# ------------------------------------------------------------\nrole_pattern = re.compile(r\"(?:,|[\\(])\\s*([A-Za-z\\s\\&\\.]+?)(?:[\\)\\,]|$)\")\ndef extract_role(spk: str) -> str:\n    match = role_pattern.search(spk)\n    if match:\n        role = match.group(1).strip().upper()\n        role = re.sub(r\"\\b(MR|MS|MRS|DR|PROF|THE|A|AN)\\b\\.?\\s*\", \"\", role)\n        return role\n    return \"\"\n\n# ------------------------------------------------------------\n# Load dataset\n# ------------------------------------------------------------\nwith open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n    clean_data = json.load(f)\n\n# ------------------------------------------------------------\n# Keep only dialogues with exactly 2 distinct roles\n# ------------------------------------------------------------\ntwo_role_data = []\nfor d in tqdm.tqdm(clean_data, desc=\"Filtering to 2-role dialogues\"):\n    roles = {extract_role(s) for s in d[\"speaker\"] if s}\n    if len(roles) == 2:\n        two_role_data.append((tuple(sorted(roles)), len(d[\"utt\"]), d))\n\nprint(f\"\\n‚úÖ Kept {len(two_role_data):,} dialogues with exactly 2 roles \"\n      f\"out of {len(clean_data):,} ({len(two_role_data)/len(clean_data)*100:.2f}%)\")\n\n# ------------------------------------------------------------\n# Compute average utterance count per combination\n# ------------------------------------------------------------\ncombo_stats = defaultdict(list)\nfor roles, n_utt, _ in two_role_data:\n    combo_stats[roles].append(n_utt)\n\ncombo_summary = []\nfor combo, utt_list in combo_stats.items():\n    combo_summary.append({\n        \"roles\": \" - \".join(combo),\n        \"count_dialogues\": len(utt_list),\n        \"avg_utterances\": np.mean(utt_list),\n        \"median_utterances\": np.median(utt_list),\n        \"max_utterances\": np.max(utt_list)\n    })\n\ndf_combo = pd.DataFrame(combo_summary).sort_values(\"count_dialogues\", ascending=False)\ndf_combo.reset_index(drop=True, inplace=True)\n\n# ------------------------------------------------------------\n# Print top 20 combinations\n# ------------------------------------------------------------\nprint(\"\\nüéôÔ∏è Top 20 two-role combinations with average dialogue length:\\n\")\nfor i, row in df_combo.head(20).iterrows():\n    print(f\"{row['roles']:60s}  {row['count_dialogues']:5d} dialogs  \"\n          f\"avg len: {row['avg_utterances']:.1f}  \"\n          f\"(median {row['median_utterances']:.0f}, max {row['max_utterances']})\")\n\n# ------------------------------------------------------------\n# Save filtered dataset (for training)\n# ------------------------------------------------------------\nonly_dialogues = [d for _, _, d in two_role_data]\n\nwith open(OUTPUT_2ROLE_PATH, \"w\", encoding=\"utf-8\") as f:\n    json.dump(only_dialogues, f, ensure_ascii=False, indent=2)\n\nprint(f\"\\nüíæ Saved {len(only_dialogues):,} two-role dialogues to '{OUTPUT_2ROLE_PATH}'\")\n\n# ------------------------------------------------------------\n# Save combination statistics\n# ------------------------------------------------------------\ndf_combo.to_csv(OUTPUT_STATS_PATH, index=False)\nprint(f\"üíæ Saved role combo stats to '{OUTPUT_STATS_PATH}'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T11:41:36.466773Z","iopub.execute_input":"2025-10-29T11:41:36.467363Z","iopub.status.idle":"2025-10-29T11:41:36.704793Z","shell.execute_reply.started":"2025-10-29T11:41:36.467337Z","shell.execute_reply":"2025-10-29T11:41:36.703978Z"}},"outputs":[{"name":"stderr","text":"Filtering to 2-role dialogues: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4216/4216 [00:00<00:00, 76118.92it/s]","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Kept 784 dialogues with exactly 2 roles out of 4,216 (18.60%)\n\nüéôÔ∏è Top 20 two-role combinations with average dialogue length:\n\nAUTHOR - HOST                                                   202 dialogs  avg len: 24.8  (median 22, max 111)\nDEMOCRAT - HOST                                                 128 dialogs  avg len: 18.9  (median 19, max 49)\nDIRECTOR - HOST                                                  94 dialogs  avg len: 22.1  (median 20, max 66)\nHOST - PRESIDENT                                                 62 dialogs  avg len: 23.8  (median 22, max 48)\nHOST - REPUBLICAN                                                62 dialogs  avg len: 18.4  (median 18, max 52)\nHOST - WRITER                                                    47 dialogs  avg len: 21.1  (median 20, max 52)\nEXECUTIVE DIRECTOR - HOST                                        30 dialogs  avg len: 21.4  (median 20, max 71)\nFOUNDER - HOST                                                   30 dialogs  avg len: 19.8  (median 20, max 32)\nCHAIRMAN - HOST                                                  29 dialogs  avg len: 20.6  (median 18, max 45)\nACTOR - HOST                                                     27 dialogs  avg len: 19.6  (median 18, max 45)\nHOST - OWNER                                                     20 dialogs  avg len: 22.3  (median 20, max 38)\nCEO - HOST                                                       18 dialogs  avg len: 21.7  (median 20, max 76)\nHOST - PROFESSOR                                                 14 dialogs  avg len: 18.4  (median 18, max 34)\nHOST - PRESIDENT AND CEO                                         12 dialogs  avg len: 26.2  (median 26, max 42)\nHOST - VICE PRESIDENT                                             9 dialogs  avg len: 22.7  (median 24, max 35)\n\nüíæ Saved 784 two-role dialogues to 'news_dialogue_two_roles.json'\nüíæ Saved role combo stats to 'two_role_combo_stats.csv'\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# -----------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"-----------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# **3. Processing the data for prompt ready sample into JSONL file for finetuning :**","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# Inspect dialogue samples from the two-role dataset\n# ============================================================\nINPUT_PATH = \"/kaggle/input/bert-embeddings/news_dialogue_two_roles.json\"\n\n# --- Load JSON data ---\nwith open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nprint(f\"‚úÖ Loaded {len(data):,} records\\n\")\n\n# --- Convert small sample to DataFrame for a quick glance ---\ndf = pd.DataFrame(data)\nprint(\"Columns:\", df.columns.tolist(), \"\\n\")\n\n# --- Show 2 random samples (compact form) ---\nsample_df = df.sample(2, random_state=42)\nfor idx, row in sample_df.iterrows():\n    print(f\"üÜî ID: {row['id']}\")\n    print(f\"üéôÔ∏è Program: {row.get('program', '')}\")\n    print(f\"üìÖ Date: {row.get('date', '')}\")\n    print(f\"üì∞ Title: {row.get('title', '')}\")\n    print(f\"üßæ Summary: {row.get('summary', '')[:180]}...\")\n    print(f\"üó£Ô∏è Number of utterances: {len(row['utt'])}\")\n    print(f\"üë• Speakers: {set(row['speaker'])}\")\n    print(\"First 5 utterances:\")\n    for u, s in list(zip(row['utt'], row['speaker']))[:3]:\n        print(f\"  {s}: {u}\")\n    print(\"-\" * 90)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T11:41:49.321774Z","iopub.execute_input":"2025-10-29T11:41:49.322071Z","iopub.status.idle":"2025-10-29T11:41:53.957988Z","shell.execute_reply.started":"2025-10-29T11:41:49.322050Z","shell.execute_reply":"2025-10-29T11:41:53.957069Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loaded 784 records\n\nColumns: ['id', 'program', 'date', 'url', 'title', 'summary', 'utt', 'speaker'] \n\nüÜî ID: NPR-41326\nüéôÔ∏è Program: All Things Considered\nüìÖ Date: 2007-03-04\nüì∞ Title: Obama, Clinton Reflect on Selma's Lengthy Shadow\nüßæ Summary: Democratic senators Hillary Clinton and Barack Obama courted black voters today with speeches in Selma, Ala., on the 42nd anniversary of the Selma March ‚Äî a civil rights demonstrat...\nüó£Ô∏è Number of utterances: 13\nüë• Speakers: {'Senator HILLARY CLINTON (Democrat, New York)', 'DEBBIE ELLIOTT, host', 'Senator BARACK OBAMA (Democrat, Illinois)'}\nFirst 5 utterances:\n  DEBBIE ELLIOTT, host: And now we return to the top story of the hour and take a few minutes to hear extended excerpts from today's speeches in Selma, Alabama by Democratic presidential hopefuls Hillary Clinton and Barack Obama.\n  DEBBIE ELLIOTT, host: Here's Senator Obama speaking at the Brown Chapel, A.M.E. Church.\n  Senator BARACK OBAMA (Democrat, Illinois): A lot of people have been asking well, you know, your father was from Africa. Your mother's a white woman from Kansas. I'm not sure that you have the same experience, and I try to explain it, you don't understand.\n------------------------------------------------------------------------------------------\nüÜî ID: NPR-41095\nüéôÔ∏è Program: All Things Considered\nüìÖ Date: 2007-11-10\nüì∞ Title: Author Ken Wells on 'Crawfish Mountain'\nüßæ Summary: Author Ken Wells layers his new novel with love, corruption and Cajun cuisine. Jacki Lyden talks with Wells about Crawfish Mountain, a story about big oil and the Louisiana wetland...\nüó£Ô∏è Number of utterances: 29\nüë• Speakers: {'Mr. KEN WELLS (Author, \"Crawfish Mountain: A Novel\")', 'JACKI LYDEN, host'}\nFirst 5 utterances:\n  JACKI LYDEN, host: This is ALL THINGS CONSIDERED from NPR News. I'm Jacki Lyden.\n  JACKI LYDEN, host: Author Ken Wells calls his new novel a gumbo Western in which characters fight over saving Louisiana's coastal marshes instead of the open range. There are love affairs, double crosses, gun play, fist fights, a chase scene on horseback dastardly bad guys, and a whole lot of beautiful scenery. Then there's a lot of serious business on the effects of oil exploration and drilling on the ecosystem of the Cajun Coast.\n  JACKI LYDEN, host: Ken Wells has been on this show before with an earlier Bayou novel, and he is from Bayou country himself. Welcome back to the show, Ken Wells.\n------------------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# ============================================================\n# Convert two-role dialogues into fine-tuning JSONL format\n# ============================================================\nINPUT_PATH = \"/kaggle/input/bert-embeddings/news_dialogue_two_roles.json\"\nOUTPUT_PATH = \"ft_news_dialogue_host_interview.jsonl\"\n\n# ------------------------------------------------------------\n# Helper functions\n# ------------------------------------------------------------\ndef merge_consecutive(utterances, speakers):\n    \"\"\"Merge consecutive lines from the same speaker.\"\"\"\n    merged = []\n    current_speaker = speakers[0]\n    current_text = [utterances[0]]\n    for u, s in zip(utterances[1:], speakers[1:]):\n        if s == current_speaker:\n            current_text.append(u)\n        else:\n            merged.append((current_speaker, \" \".join(current_text)))\n            current_speaker, current_text = s, [u]\n    merged.append((current_speaker, \" \".join(current_text)))\n    return merged\n\ndef identify_host(speakers):\n    for s in speakers:\n        if \"host\" in s.lower():\n            return s\n    return None\n\n# ------------------------------------------------------------\n# Professional system prompt templates\n# ------------------------------------------------------------\ndef build_system_prompt(title, summary):\n    \"\"\"Dynamic prompt generation with professional context injection.\"\"\"\n    base_prompt = (\n        \"You are an experienced journalist conducting a live interview. \"\n        \"Your style is conversational, respectful, and inquisitive. \"\n        \"You guide discussions with clear, insightful questions that encourage depth and authenticity. \"\n        \"You respond naturally, reference prior remarks when relevant, and balance professionalism with empathy. \"\n        \"If the guest provides complex or emotional information, acknowledge it gracefully and keep the discussion coherent.\"\n    )\n\n    # 50% of samples include contextual metadata\n    if random.random() < 0.5 and title:\n        context_prompt = (\n            f\"Today's topic: {title.strip()} \"\n            f\"‚Äî Background: {summary.strip() if summary else 'no summary available.'} \"\n            \"Keep your questions grounded in this context, but do not rigidly quote or summarize it. \"\n            \"Your goal is to create an engaging dialogue that flows naturally while remaining factually grounded.\"\n        )\n        return f\"{base_prompt}\\n\\n{context_prompt}\"\n    else:\n        fallback_prompt = (\n            \"Engage the guest naturally. Ask follow-up questions that build on what they say. \"\n            \"Avoid monologues; favor short, well-phrased questions. End gracefully when appropriate.\"\n        )\n        return f\"{base_prompt}\\n\\n{fallback_prompt}\"\n\n# ------------------------------------------------------------\n# Load dataset\n# ------------------------------------------------------------\nwith open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nprint(f\"‚úÖ Loaded {len(data):,} dialogues\")\n\n# ------------------------------------------------------------\n# Transform dialogues\n# ------------------------------------------------------------\nrecords = []\nfor d in tqdm.tqdm(data, desc=\"Converting\"):\n    host = identify_host(d[\"speaker\"])\n    if not host:\n        continue\n\n    merged = merge_consecutive(d[\"utt\"], d[\"speaker\"])\n    sys_prompt = build_system_prompt(d.get(\"title\", \"\"), d.get(\"summary\", \"\"))\n\n    messages = [{\"role\": \"system\", \"content\": sys_prompt.strip()}]\n\n    for spk, utt in merged:\n        if not utt.strip():\n            continue\n        role = \"assistant\" if spk == host else \"user\"\n        messages.append({\"role\": role, \"content\": utt.strip()})\n\n    if sum(1 for m in messages if m[\"role\"] == \"assistant\") >= 1 and \\\n       sum(1 for m in messages if m[\"role\"] == \"user\") >= 1:\n        records.append({\"messages\": messages})\n\nprint(f\"‚úÖ Prepared {len(records):,} usable dialogues\")\n\n# ------------------------------------------------------------\n# Save as JSONL\n# ------------------------------------------------------------\nwith open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n    for r in records:\n        json.dump(r, f, ensure_ascii=False)\n        f.write(\"\\n\")\n\nprint(f\"üíæ Saved fine-tuning file to '{OUTPUT_PATH}'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T11:42:18.567356Z","iopub.execute_input":"2025-10-29T11:42:18.567692Z","iopub.status.idle":"2025-10-29T11:42:18.742368Z","shell.execute_reply.started":"2025-10-29T11:42:18.567670Z","shell.execute_reply":"2025-10-29T11:42:18.741618Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loaded 784 dialogues\n","output_type":"stream"},{"name":"stderr","text":"Converting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 784/784 [00:00<00:00, 48537.02it/s]","output_type":"stream"},{"name":"stdout","text":"‚úÖ Prepared 784 usable dialogues\nüíæ Saved fine-tuning file to 'ft_news_dialogue_host_interview.jsonl'\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# ============================================================\n#  Add \"Let's begin the interview.\" after system message\n#  and merge consecutive messages with same role\n# ============================================================\nOLD_PATH = \"/kaggle/input/bert-embeddings/ft_news_dialogue_host_interview.jsonl\"\nNEW_PATH = \"ft_news_dialogue_FINAL_2.jsonl\"\n\ndef add_intro_and_merge(example):\n    msgs = example[\"messages\"]\n    fixed = []\n    # --- Keep system message if present ---\n    if msgs and msgs[0][\"role\"] == \"system\":\n        fixed.append(msgs[0])\n        msgs = msgs[1:]\n    # --- Always insert neutral intro user message ---\n    fixed.append({\"role\": \"user\", \"content\": \"Let's begin the interview.\"})\n    # --- Merge consecutive messages with same role ---\n    for msg in msgs:\n        if fixed and fixed[-1][\"role\"] == msg[\"role\"]:\n            # Merge text if same role as previous\n            fixed[-1][\"content\"] += \" \" + msg[\"content\"].strip()\n        else:\n            fixed.append(msg)\n    example[\"messages\"] = fixed\n    return example\n\n# --- Process and save new file ---\nwith open(OLD_PATH, \"r\", encoding=\"utf-8\") as fin, open(NEW_PATH, \"w\", encoding=\"utf-8\") as fout:\n    for line in fin:\n        example = json.loads(line)\n        example = add_intro_and_merge(example)\n        fout.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\nprint(f\"‚úÖ New merged dataset saved at: {NEW_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T11:42:41.597211Z","iopub.execute_input":"2025-10-29T11:42:41.598099Z","iopub.status.idle":"2025-10-29T11:42:41.902249Z","shell.execute_reply.started":"2025-10-29T11:42:41.598057Z","shell.execute_reply":"2025-10-29T11:42:41.901442Z"}},"outputs":[{"name":"stdout","text":"‚úÖ New merged dataset saved at: ft_news_dialogue_FINAL_2.jsonl\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# ============================================================\n#  Validate final dataset structure (role alternation)\n# ============================================================\nFILE_PATH = \"/kaggle/input/bert-embeddings/ft_news_dialogue_FINAL_2.jsonl\"\n\nbad_rows = []\ndouble_user = []\ndouble_assistant = []\n\nwith open(FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n    for i, line in enumerate(f, start=1):\n        ex = json.loads(line)\n        msgs = ex.get(\"messages\", [])\n\n        if not msgs:\n            bad_rows.append(i)\n            continue\n\n        # --- Check if system is followed by user ---\n        if msgs[0][\"role\"] == \"system\":\n            if len(msgs) < 2 or msgs[1][\"role\"] != \"user\":\n                bad_rows.append(i)\n\n        # --- Check for consecutive duplicate roles ---\n        for j in range(1, len(msgs)):\n            if msgs[j][\"role\"] == msgs[j - 1][\"role\"]:\n                if msgs[j][\"role\"] == \"user\":\n                    double_user.append((i, j))\n                elif msgs[j][\"role\"] == \"assistant\":\n                    double_assistant.append((i, j))\n\n# --- Summary report ---\nprint(\"=\"*60)\nprint(\"üîç Dataset Validation Summary\")\nprint(\"=\"*60)\nprint(f\"Total rows checked: {i}\")\nprint(f\"‚ùå Rows with system not followed by user: {len(bad_rows)}\")\nprint(f\"‚ö†Ô∏è  Consecutive user-user pairs: {len(double_user)}\")\nprint(f\"‚ö†Ô∏è  Consecutive assistant-assistant pairs: {len(double_assistant)}\")\nprint(\"=\"*60)\n\nif bad_rows:\n    print(\"Example problematic rows (system‚Üínon-user):\", bad_rows[:5])\nif double_user:\n    print(\"Example user-user rows:\", double_user[:5])\nif double_assistant:\n    print(\"Example assistant-assistant rows:\", double_assistant[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T11:42:51.186644Z","iopub.execute_input":"2025-10-29T11:42:51.186933Z","iopub.status.idle":"2025-10-29T11:42:51.491498Z","shell.execute_reply.started":"2025-10-29T11:42:51.186914Z","shell.execute_reply":"2025-10-29T11:42:51.490583Z"}},"outputs":[{"name":"stdout","text":"============================================================\nüîç Dataset Validation Summary\n============================================================\nTotal rows checked: 784\n‚ùå Rows with system not followed by user: 0\n‚ö†Ô∏è  Consecutive user-user pairs: 0\n‚ö†Ô∏è  Consecutive assistant-assistant pairs: 0\n============================================================\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# -----------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"-----------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# **4. Finetuning Using Mistral 7B v3 :**","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# 2. Load and Prepare Dataset\n# ============================================================\nDATA_PATH = \"/kaggle/input/bert-embeddings/ft_news_dialogue_FINAL_2.jsonl\"\n\nwith open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n    data = [json.loads(l) for l in f]\n\nrandom.shuffle(data)\nn = len(data)\ntrain_data = data[:int(0.8*n)]\neval_data  = data[int(0.8*n):int(0.9*n)]\ntest_data  = data[int(0.9*n):]\n\ntrain_ds = Dataset.from_list(train_data)\neval_ds  = Dataset.from_list(eval_data)\ntest_ds  = Dataset.from_list(test_data)\ndataset = {\"train\": train_ds, \"eval\": eval_ds, \"test\": test_ds}\n\nprint(f\"‚úÖ Train: {len(train_ds)}, Eval: {len(eval_ds)}, Test: {len(test_ds)}\")\nprint(dataset[\"train\"][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T12:41:56.896893Z","iopub.execute_input":"2025-10-29T12:41:56.897490Z","iopub.status.idle":"2025-10-29T12:41:57.051195Z","shell.execute_reply.started":"2025-10-29T12:41:56.897460Z","shell.execute_reply":"2025-10-29T12:41:57.050220Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Train: 627, Eval: 78, Test: 79\n{'messages': [{'content': \"You are an experienced journalist conducting a live interview. Your style is conversational, respectful, and inquisitive. You guide discussions with clear, insightful questions that encourage depth and authenticity. You respond naturally, reference prior remarks when relevant, and balance professionalism with empathy. If the guest provides complex or emotional information, acknowledge it gracefully and keep the discussion coherent.\\n\\nToday's topic: Rep. Maxine Waters on Blacks and Immigration ‚Äî Background: Where do black lawmakers stand on the issue of undocumented workers? U.S. Rep. Maxine Waters (D-CA), discusses the issue with Ed Gordon. Waters' district includes Los Angeles and surrounding cities, one of the hotbeds of protests against an immigration crackdown. Keep your questions grounded in this context, but do not rigidly quote or summarize it. Your goal is to create an engaging dialogue that flows naturally while remaining factually grounded.\", 'role': 'system'}, {'content': \"Let's begin the interview.\", 'role': 'user'}, {'content': \"There is of course a lot at stake in the fight over immigration reform. We just heard about the economic implications. But there's also the question of political clout. This is especially pertinent to African Americans, who until recently were the largest minority in the country. But some say African Americans have been virtually watching from the sidelines as the debate plays itself out. Joining us now, California Congresswoman Maxine Waters. Her congressional district includes Los Angeles, one of the hotbeds of immigration protest; and she's pushing what she call's a bipartisan solution to a bipartisan problem. Representative Waters, thanks for joining us. Always good to have you.\", 'role': 'assistant'}, {'content': 'Good to be with you. How are you doing?', 'role': 'user'}, {'content': \"Good, thank you. You just heard what Mr. Katz suggested. I'm curious whether you believe that these undocumented workers are taking jobs away from Americans. We hear the debate that they're taking only jobs that Americans don't want.\", 'role': 'assistant'}, {'content': \"Well, first let me say this before I go directly to that. We have a huge problem. This immigration problem is big. It's a crisis. And we can't get around it anymore. It's got to be dealt with. We're going to come out of this Congress with immigration reform, and it's going to have several components. One is there's going to be more border security to stop the influx of immigrants from coming in. Number two, there is going to be some kind of a guest worker program. It may not be the same guest worker program that the President is advocating at this time, but there will be some kind of guest worker program. And the third component will be a way by which undocumented immigrants can earn legalization. The 11 million that are here without documents will, without documents, will be able to earn. We'll set the criteria, it will include paying taxes and some other kinds of things, but that will happen. Now, as for the jobs. It is important that we fight for livable wages for all workers. Yes, Mexican immigrants, for example, take jobs where they're exploited and their employers are paying lower than minimum wage. African American do want jobs. It is not that immigrants are taking jobs that African American don't want. But African American know what is a fair wage, what is minimum wage. They know the law. And so they want these jobs to pay a decent wage, a livable wage, and, you know, comply with minimum wage laws and all of that. It's not that they don't want the jobs, they just want what they have, what they should have coming to them.\", 'role': 'user'}, {'content': \"Maxine Waters, are you concerned that some of the misinformation, if you will, that's being put out there will cause a riff between communities and cause more tension than need be?\", 'role': 'assistant'}, {'content': \"Well, I want to tell you, there are misunderstandings and there are people who think that, you know, immigrants are taking jobs or that they're getting favored. But there are a lot of people who have been living door by door, side by side with immigrants for the last forty years in South Los Angeles. If you go deep into our neighborhoods, you will find that Latinos, some of them undocumented, got into the United States, never got their documentation, but they've been living in these neighborhoods, and they get along very well with African Americans. Some of the younger people have competition problems and it spills over into the gangs, but we have to work through that. I mean, these are problems that America, you know, must understand, and they're not foreign to us. I mean, we had the same kind of problem with African American moving into neighborhoods that were predominately white. So yeah, we've got problems, but the fact of the matter is our undocumented immigrants are not going to go away. Eleven mil1ion people are not going to be deported. We're not going to be able to detain them or ship them out as some of these Republicans would have you believe. We've got to solve the problem.\", 'role': 'user'}, {'content': \"How realistic is it to believe that we're going to see a bipartisan effort to really close this out? We had Harry Reid on the program earlier this week, and he made it clear in no uncertain terms that the President is really going to have to look at this guest worker program and really be realistic about what it takes to make this real.\", 'role': 'assistant'}, {'content': \"Yeah. Well, I think it's inevitable that we come to -- we will come to some agreement. There will be a compromise. It's going to be bitter, and you have, you know, some right-wing conservatives who are digging in at this time with crazy bills like the Sensenbrenner bill that literally talks about making felons out of all of the undocumented. That is not realistic. That's not going to happen. We don't have the money, the jails, the personnel, none of that to deal with it that way. And then they talk kind of, you know, about somehow just punishing the employers and the jobs will dry up. Many of these jobs are in the underground economy. You have Mexican workers and other immigrant workers who don't go to, you know, the traditional places to find jobs. They clean out yards. They paint for, you know, Miss Jones down the street. They put up fences. They do all kind of work, and a lot of that money is in the underground economy. So when you talk about you're going to dry up the jobs from the employers, you know, they're thinking about the traditional employers. But many of the employers are, you know, the lady down the street, the man -- the church around the corner. So you know, immigrants learn how to survive and they earn money doing all kinds of jobs, and that's not going to go away, and they're not going to go back because somehow you're going to fine Wal-Mart for hiring immigrants. They're going to still be here.\", 'role': 'user'}, {'content': 'How much of this is fair to say, Maxine Waters, that this is a problem that continued to grow, continued to grow, continued to grow, and frankly, both sides of the aisle on Washington put it on the backburner and now the chickens have come home to roost?', 'role': 'assistant'}, {'content': \"Well, I think we have not done what we should have done, number one, to secure the border. It takes a lot of money, but you know, we are fighting a war where we're spending darn near 300 billion dollars, so you know, we have the resources to secure the border if we really, you know, had the will to do so. And you're right, we have needed immigration reform. We have had a schizophrenic policy. You've had part of the business community and the agriculture community that want these people coming in, working for them. They exploited many of them, work and sleep in the fields at night without decent housing. That's been all right. You know, we've turned a blind eye to that kind of exploitation. And you will find the Chamber of Commerce and others fighting now to see how they can hold on to this cheap, cheap labor.\", 'role': 'user'}, {'content': 'All right. Democratic Congresswoman Maxine Waters of California. Always good to have you with us, Congresswoman. Thanks.', 'role': 'assistant'}, {'content': 'Thank you very much. Bye.', 'role': 'user'}]}\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# ============================================================\n# 3. Load Base Model & Tokenizer (QLoRA Setup)\n# ============================================================\nmodel_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    load_in_4bit=True,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\"\n)\n\nmodel = prepare_model_for_kbit_training(model)\n\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\n        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n        \"gate_proj\", \"up_proj\", \"down_proj\"\n    ],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T12:42:01.406265Z","iopub.execute_input":"2025-10-29T12:42:01.407103Z","iopub.status.idle":"2025-10-29T12:42:56.319659Z","shell.execute_reply.started":"2025-10-29T12:42:01.407077Z","shell.execute_reply":"2025-10-29T12:42:56.318803Z"}},"outputs":[{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55f0975c56354ee88a80af8ec1461b50"}},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"# --- 1. Log in to W&B using Kaggle Secrets ---\n# (This securely gets the key you just added)\ntry:\n    api_key = UserSecretsClient().get_secret(\"WANDB_API_KEY\")\n    os.environ[\"WANDB_API_KEY\"] = api_key\n    print(\"‚úÖ W&B login successful using Kaggle Secret.\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Could not log in using Kaggle Secrets. Error: {e}\")\n    print(\"Please go to 'Add-ons' > 'Secrets' and add your W&B API key.\")\n\n# --- 2. Set your W&B Project and Entity names ---\n# (This tells W&B where to send the run)\nos.environ[\"WANDB_PROJECT\"] = \"mistral7b-newsbot-ft\"  # You can change this project name\nos.environ[\"WANDB_ENTITY\"] = \"adam-pro-01-esprit\"    # This is your team name from the screenshot","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T12:44:03.566152Z","iopub.execute_input":"2025-10-29T12:44:03.566460Z","iopub.status.idle":"2025-10-29T12:44:03.653468Z","shell.execute_reply.started":"2025-10-29T12:44:03.566435Z","shell.execute_reply":"2025-10-29T12:44:03.652816Z"}},"outputs":[{"name":"stdout","text":"‚úÖ W&B login successful using Kaggle Secret.\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# ============================================================\n# 4. Training Configuration\n# ============================================================\nsft_config = SFTConfig(\n    output_dir=\"./mistral7b-newsbot-ft\",\n    num_train_epochs=2,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=8,\n    learning_rate=2e-5,\n    save_strategy=\"epoch\",\n    logging_steps=15,\n    bf16=True,\n    optim=\"paged_adamw_8bit\",\n    warmup_ratio=0.03,\n    lr_scheduler_type=\"cosine\",\n    report_to=\"wandb\",  \n)\n\n# ============================================================\n# 5. Fine-tune with TRL SFTTrainer\n# ============================================================\n# (This code is fixed, with invisible characters removed)\nprint(\"Initializing SFTTrainer...\")\ntrainer = SFTTrainer(\n    model=model,\n    args=sft_config,\n    peft_config=lora_config,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"eval\"],\n)\n\nprint(\"Starting trainer.train()... This will create a run in W&B.\")\ntrainer.train()\n\nprint(\"‚úÖ Training complete! Check your W&B dashboard.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T12:44:13.736413Z","iopub.execute_input":"2025-10-29T12:44:13.736705Z"}},"outputs":[{"name":"stdout","text":"Initializing SFTTrainer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/627 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d179e715857741b88d91b1c6e19dd923"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/627 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94da41be27044db5ba30c61edceada4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/78 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0ae7ed5dbce4a5bad200c2aef8bd90f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating eval dataset:   0%|          | 0/78 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54a959c979224b6999af4375f1abbca2"}},"metadata":{}},{"name":"stdout","text":"Starting trainer.train()... This will create a run in W&B.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='158' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 63/158 3:20:05 < 5:11:36, 0.01 it/s, Epoch 0.79/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>15</td>\n      <td>2.341000</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.132200</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>2.078900</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>2.041400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# 6. Save Trained Adapter\n# ============================================================\nSAVE_DIR = \"mistral7b-newsbot-lora\"\ntrainer.model.save_pretrained(SAVE_DIR)\ntokenizer.save_pretrained(SAVE_DIR)\n\nprint(\"‚úÖ LoRA fine-tuning complete and model saved at:\", SAVE_DIR)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"-------------------","metadata":{}},{"cell_type":"markdown","source":"-----------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"-----------------------------------------------------------------------","metadata":{}}]}